{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91c3208a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the necessary modules\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import linear_model, svm, ensemble, datasets, model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d7f43869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DESCR', 'data', 'data_module', 'feature_names', 'filename', 'frame', 'target', 'target_names']\n"
     ]
    }
   ],
   "source": [
    "# Loading the dataset\n",
    "\n",
    "dataset = datasets.load_iris()\n",
    "print(dir(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4b45fa68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object _BaseKFold.split at 0x00000179A2FDDD90>\n",
      "(array([2, 3, 4, 5]), array([0, 1]))\n",
      "(array([0, 1, 3, 4, 5]), array([2]))\n",
      "(array([0, 1, 2, 4, 5]), array([3]))\n",
      "(array([0, 1, 2, 3, 5]), array([4]))\n",
      "(array([0, 1, 2, 3, 4]), array([5]))\n",
      "[2 3 4 5] [0 1]\n",
      "[0 1 3 4 5] [2]\n",
      "[0 1 2 4 5] [3]\n",
      "[0 1 2 3 5] [4]\n",
      "[0 1 2 3 4] [5]\n"
     ]
    }
   ],
   "source": [
    "# Splitting the data into 'k' folds\n",
    "\n",
    "kf = model_selection.KFold(n_splits = 5)\n",
    "\n",
    "print(kf.split([1, 2, 3, 4, 5, 6]))\n",
    "\n",
    "for x in kf.split([1, 3, 5, 7, 9, 11]):\n",
    "    print(x)\n",
    "    \n",
    "for train_index, test_index in kf.split([2, 4, 6, 8, 10, 12]):\n",
    "    print(train_index, test_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9c171ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stratified 'k' fold -> Distributes each classification category uniformly\n",
    "\n",
    "kf = model_selection.StratifiedKFold(n_splits = 5)\n",
    "\n",
    "for train_index, test_index in kf.split(dataset.data, dataset.target):\n",
    "    X_train, X_test, y_train, y_test = dataset.data[train_index], dataset.data[test_index], dataset.target[train_index], dataset.target[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b6a64405",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9666666666666667, 1.0, 0.9333333333333333, 0.9666666666666667, 1.0]\n",
      "[0.9666666666666667, 1.0, 0.9666666666666667, 0.9666666666666667, 1.0]\n",
      "[0.9666666666666667, 0.9666666666666667, 0.9333333333333333, 0.9333333333333333, 1.0]\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model performance\n",
    "\n",
    "lg = linear_model.LogisticRegression(max_iter = 10000)\n",
    "s = svm.SVC(kernel = \"linear\")\n",
    "rf = ensemble.RandomForestClassifier(n_estimators = 50)\n",
    "\n",
    "lg_scores, s_scores = [], []\n",
    "rf_scores = s_scores.copy()\n",
    "\n",
    "def train_model(model, X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    return model.score(X_test, y_test)\n",
    "\n",
    "kf = model_selection.StratifiedKFold(n_splits = 5)\n",
    "\n",
    "for train_index, test_index in kf.split(dataset.data, dataset.target):\n",
    "    X_train, X_test, y_train, y_test = dataset.data[train_index], dataset.data[test_index], dataset.target[train_index], dataset.target[test_index]\n",
    "    lg_scores.append(train_model(lg, X_train, X_test, y_train, y_test))\n",
    "    s_scores.append(train_model(s, X_train, X_test, y_train, y_test))\n",
    "    rf_scores.append(train_model(rf, X_train, X_test, y_train, y_test))\n",
    "    \n",
    "print(lg_scores)\n",
    "print(s_scores)\n",
    "print(rf_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9070bb47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9733333333333334\n",
      "0.9800000000000001\n",
      "0.96\n"
     ]
    }
   ],
   "source": [
    "# Average Scores\n",
    "\n",
    "print(sum(lg_scores) / len(lg_scores))\n",
    "print(sum(s_scores) / len(s_scores))\n",
    "print(sum(rf_scores) / len(rf_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f01825b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.96666667 1.         0.93333333 0.96666667 1.        ]\n",
      "[0.96666667 1.         0.96666667 0.96666667 1.        ]\n",
      "[0.96666667 0.96666667 0.9        0.96666667 1.        ]\n"
     ]
    }
   ],
   "source": [
    "# Using cross_val_score to find the accuracy directly  (5 folds by default)\n",
    "\n",
    "print(model_selection.cross_val_score(linear_model.LogisticRegression(max_iter = 1000), dataset.data, dataset.target))\n",
    "print(model_selection.cross_val_score(svm.SVC(kernel = \"linear\"), dataset.data, dataset.target))\n",
    "print(model_selection.cross_val_score(ensemble.RandomForestClassifier(n_estimators = 50), dataset.data, dataset.target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "bf5a72d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conclusion : SVM Performs Better in Classification"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
